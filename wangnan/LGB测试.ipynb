{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T06:00:11.441354Z",
     "start_time": "2018-08-22T06:00:10.146941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#lgmodel = lgb.LGBMClassifier(model_file='model-transR.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T00:51:42.547520Z",
     "start_time": "2018-08-22T00:37:46.631447Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_movie_info = pd.read_csv('/data/data/all_movie_info_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T00:56:37.846935Z",
     "start_time": "2018-08-22T00:56:37.685935Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in all_movie_info.select_dtypes('object').columns:\n",
    "    lbl = LabelEncoder()\n",
    "    all_movie_info[i] = lbl.fit_transform(all_movie_info[i].fillna(-1).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:00:47.064457Z",
     "start_time": "2018-08-22T00:57:03.058206Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_name = [i for i in all_movie_info if i not in ['star']]\n",
    "train_data,valid_data,train_label,valid_label = train_test_split(all_movie_info[feature_name],all_movie_info['star'],random_state=1998,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:22:16.286624Z",
     "start_time": "2018-08-22T01:21:35.177047Z"
    }
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(train_data[feature_name], label=train_label.values)\n",
    "dval = lgb.Dataset(valid_data[feature_name], label=valid_label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:26:23.296446Z",
     "start_time": "2018-08-22T01:26:23.289740Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.1,\n",
    "          'metric': ['auc','binary_logloss'],\n",
    "          'objective': 'binary',\n",
    "          'nthread': 32,\n",
    "          'num_leaves': 16,\n",
    "          'colsample_bytree': 0.9,\n",
    "          'bagging_fraction' : 0.9,\n",
    "          'bagging_freq' : 10,\n",
    "          'seed' : 2018,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T02:05:08.867633Z",
     "start_time": "2018-08-22T01:30:29.806715Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's binary_logloss: 0.152222\tvalid_0's auc: 1\n",
      "[20]\tvalid_0's binary_logloss: 0.053906\tvalid_0's auc: 1\n",
      "[30]\tvalid_0's binary_logloss: 0.0201119\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's binary_logloss: 0.00766463\tvalid_0's auc: 1\n",
      "[50]\tvalid_0's binary_logloss: 0.00282877\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's binary_logloss: 0.00110642\tvalid_0's auc: 1\n",
      "[70]\tvalid_0's binary_logloss: 0.000426672\tvalid_0's auc: 1\n",
      "[80]\tvalid_0's binary_logloss: 0.000202648\tvalid_0's auc: 1\n",
      "[90]\tvalid_0's binary_logloss: 0.000106029\tvalid_0's auc: 0.999999\n",
      "[100]\tvalid_0's binary_logloss: 6.84093e-05\tvalid_0's auc: 0.999999\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.184747\tvalid_0's auc: 1\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.train(params, dtrain, 1000, dval, verbose_eval=10,early_stopping_rounds=100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T02:07:46.832694Z",
     "start_time": "2018-08-22T02:07:46.752848Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# dump model with pickle\n",
    "with open('model.pkl', 'wb') as fout:\n",
    "    pickle.dump(gbm, fout)\n",
    "# load model with pickle to predict\n",
    "with open('model.pkl', 'rb') as fin:\n",
    "    pkl_bst = pickle.load(fin)\n",
    "# can predict with any iteration when loaded in pickle way\n",
    "y_pred = pkl_bst.predict(X_test, num_iteration=7)\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('model-transR-more-negative.pkl', 'wb') as fout:\n",
    "    pickle.dump(lgb_model, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------remove history, more negative example---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T06:00:17.466871Z",
     "start_time": "2018-08-22T06:00:17.417920Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model with pickle to predict\n",
    "with open('model-transR-more-negative.pkl', 'rb') as fin:\n",
    "    pkl_bst = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T06:00:20.618994Z",
     "start_time": "2018-08-22T06:00:20.612941Z"
    }
   },
   "outputs": [],
   "source": [
    "def genTest(uid, minfo_canfile):\n",
    "    '''\n",
    "    uid: 待测试的user_id\n",
    "    minfo_canfile: 是候选集电影集合的dataframe，包含除了 uid 、 star %debug影特征\n",
    "    返回值：返回添加了uid列的dataframe\n",
    "    '''\n",
    "    candf = pd.read_csv(minfo_canfile)\n",
    "    userlist = []\n",
    "    for i in range(1000):\n",
    "        userlist.append(uid)\n",
    "    \n",
    "    candf['uid'] = userlist\n",
    "    return candf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T06:00:22.896589Z",
     "start_time": "2018-08-22T06:00:22.893043Z"
    }
   },
   "outputs": [],
   "source": [
    "def isnotin(thelist,element):\n",
    "    if element in thelist:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T06:00:27.272206Z",
     "start_time": "2018-08-22T06:00:27.257411Z"
    }
   },
   "outputs": [],
   "source": [
    "def genFinalResult(uidList,destFile,minfo_canfile,model):\n",
    "    '''\n",
    "    uidList: test文件，每一行是待测试的 uidid\n",
    "    destFile: 结果的输出文件，保存格式为每行 uid\\tmid1,mid2,...\n",
    "    minfo_canfile: 是候选集电影集合的dataframe，包含除了 uid 、 star %debug影特征\n",
    "    model: 已经训练好的model\n",
    "    '''\n",
    "    \n",
    "    # 读取 uidList 中的 uid到 list\n",
    "    ulist = []\n",
    "    with open(uidList) as f:\n",
    "        for line in f:\n",
    "            uid = line.strip()\n",
    "            if uid not in ulist:\n",
    "                ulist.append(int(uid)) # ulist type: str\n",
    "            \n",
    "    dest = open(destFile,'w')\n",
    "    \n",
    "    # 读取 测试用户的 观影记录\n",
    "    with open('watched_dict.pickle','rb') as f:\n",
    "        hisdict = pickle.load(f)\n",
    "    \n",
    "    icount = 0\n",
    "    \n",
    "    # 对 list 中每一个 uid，生成推荐的50部的电影列表\n",
    "    for utem in ulist:\n",
    "        thedf = genTest(int(utem), minfo_canfile)\n",
    "        hislist = hisdict[utem]\n",
    "        hislist = set(hislist)\n",
    "        \n",
    "        fil_df = thedf[thedf['mid'].map(lambda x:isnotin(hislist,x))]\n",
    "        \n",
    "        # 预处理\n",
    "        for i in fil_df.select_dtypes('object').columns:\n",
    "            lbl = LabelEncoder()\n",
    "            fil_df[i] = lbl.fit_transform(fil_df[i].fillna(-1).astype(str))\n",
    "            \n",
    "        # 预测，选概率最高的前50    \n",
    "        result = model.predict(fil_df) \n",
    "        fil_df['probability'] = result\n",
    "        sorted_df = fil_df.sort_values('probability',ascending = False)\n",
    "        retop50 = pd.DataFrame.head(sorted_df, 50)['mid'].tolist()\n",
    "        \n",
    "        rec_str = \"\"\n",
    "        \n",
    "        for mmid in retop50:\n",
    "            rec_str = rec_str + str(mmid) + \",\"\n",
    "\n",
    "        rec_str = rec_str[:-1]\n",
    "        newline = str(utem) + '\\t' + rec_str + '\\n'\n",
    "        dest.write(newline)\n",
    "        icount = icount + 1\n",
    "        if icount % 100 == 0 :\n",
    "            print(\"The \" + str(icount) + \" th uid predicted ...\")\n",
    "        \n",
    "    dest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-22T06:00:55.362Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 100 th uid predicted ...\n",
      "The 200 th uid predicted ...\n",
      "The 300 th uid predicted ...\n",
      "The 400 th uid predicted ...\n"
     ]
    }
   ],
   "source": [
    "genFinalResult(\"UserMovie_test2.txt\",\"result_hot1000_rmhistory_4vs1.txt\",\"minfo_candidate_hottest1000.csv\",pkl_bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T04:01:20.059551Z",
     "start_time": "2018-08-21T04:01:20.025296Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  split_score    gain_score\n",
      "0              mid         1580  1.326666e+10\n",
      "1              r_1         1719  1.386412e+08\n",
      "2              r_2         2211  5.821983e+07\n",
      "3              r_3          109  9.280557e+06\n",
      "4              r_4           95  1.250871e+05\n",
      "5              r_5           84  2.830967e+06\n",
      "6              r_6           81  1.538176e+05\n",
      "7              r_7          106  5.359057e+06\n",
      "8              r_8          135  2.627071e+07\n",
      "9              r_9           86  2.408912e+06\n",
      "10            r_10          119  2.974307e+06\n",
      "11            r_11          106  1.889031e+07\n",
      "12            r_12          117  7.130919e+05\n",
      "13            r_13           93  7.876261e+05\n",
      "14            r_14          112  8.016569e+05\n",
      "15            r_15           88  2.087294e+06\n",
      "16            r_16          135  1.639676e+09\n",
      "17            r_17          106  2.228031e+06\n",
      "18            r_18          100  2.491491e+06\n",
      "19            r_19           93  1.376509e+06\n",
      "20            r_20          102  3.552013e+07\n",
      "21            r_21          105  1.489117e+06\n",
      "22            r_22           85  2.123168e+05\n",
      "23            r_23          124  1.286873e+06\n",
      "24            r_24          111  1.595316e+05\n",
      "25            r_25          136  4.179937e+06\n",
      "26            r_26           93  6.837006e+05\n",
      "27            r_27           98  1.548856e+06\n",
      "28            r_28           87  8.357798e+05\n",
      "29            r_29          118  7.026072e+05\n",
      "..             ...          ...           ...\n",
      "39            r_39          123  1.550861e+05\n",
      "40            r_40           95  1.021029e+05\n",
      "41            r_41          105  3.121792e+06\n",
      "42            r_42          106  2.317750e+05\n",
      "43            r_43          146  8.700826e+05\n",
      "44            r_44          105  6.775879e+06\n",
      "45            r_45           98  4.895891e+05\n",
      "46            r_46          111  2.629394e+07\n",
      "47            r_47          140  5.509010e+05\n",
      "48            r_48           69  6.466221e+05\n",
      "49            r_49           97  4.481349e+08\n",
      "50            r_50          128  4.407582e+08\n",
      "51            name          129  1.224393e+06\n",
      "52        director          131  1.780442e+06\n",
      "53    scriptwriter          136  7.869500e+05\n",
      "54     mainPlayers          125  3.393788e+06\n",
      "55      categories          108  5.486933e+05\n",
      "56  productCountry          124  3.787901e+06\n",
      "57        duration           96  9.116110e+05\n",
      "58    releasedTime          112  1.695831e+06\n",
      "59            tags          105  1.407583e+06\n",
      "60     ratingCount         1055  1.118198e+07\n",
      "61           star5          158  1.117001e+08\n",
      "62           star4          876  7.403552e+08\n",
      "63           star3          210  1.061880e+09\n",
      "64           star2          221  1.313645e+10\n",
      "65           star1          243  4.404007e+08\n",
      "66        language          174  5.968796e+07\n",
      "67       timestamp          162  3.993046e+08\n",
      "68             uid           95  6.662423e+05\n",
      "\n",
      "[69 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame as DF\n",
    "fi = DF()\n",
    "feature_name = [i for i in thedf.columns]\n",
    "fi['name'] = feature_name\n",
    "fi['split_score'] = pkl_bst.feature_importance(importance_type='split')\n",
    "fi['gain_score'] = pkl_bst.feature_importance(importance_type='gain')\n",
    "print(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:04:34.955088Z",
     "start_time": "2018-08-21T12:04:34.940759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'set'>\n"
     ]
    }
   ],
   "source": [
    "a = ['a','b','6']\n",
    "print(type(a))\n",
    "\n",
    "a = set(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
